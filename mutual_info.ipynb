{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Script to calculate Mutual Information between two discrete random variables\n",
    "\n",
    "Roberto Maestre - rmaestre@gmail.com\n",
    "Bojan Mihaljevic - boki.mihaljevic@gmail.com\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "from numpy import array, shape, where, in1d\n",
    "import math\n",
    "import time\n",
    "import nose\n",
    "\n",
    "class InformationTheoryTool:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # Check if all rows have the same length\n",
    "        assert (len(data.shape) == 2)\n",
    "        # Save data\n",
    "        self.data = data\n",
    "        self.n_rows = data.shape[0]\n",
    "        self.n_cols = data.shape[1]\n",
    "        \n",
    "        \n",
    "    def single_entropy(self, x_index, log_base, debug=False):\n",
    "        \"\"\"\n",
    "        Calculate the entropy of a random variable\n",
    "        \"\"\"\n",
    "        # Check if index are into the bounds\n",
    "        assert (x_index >= 0 and x_index <= self.n_rows)\n",
    "        # Variable to return entropy\n",
    "        summation = 0.0\n",
    "        # Get unique values of random variables\n",
    "        values_x = set(self.data[x_index])\n",
    "        # Print debug info\n",
    "        if debug:\n",
    "            print('Entropy of')\n",
    "            print(self.data[x_index])\n",
    "        # For each random value\n",
    "        for value_x in values_x:\n",
    "            px = shape(where(self.data[x_index] == value_x))[1] / self.n_cols\n",
    "            if px > 0.0:\n",
    "                summation += px * math.log(px, log_base)\n",
    "            if debug:\n",
    "                print(f'({value_x}) px:{px}')\n",
    "        if summation == 0.0:\n",
    "            return summation\n",
    "        else:\n",
    "            return -summation\n",
    "        \n",
    "        \n",
    "    def entropy(self, x_index, y_index, log_base, debug=False):\n",
    "        \"\"\"\n",
    "        Calculate the entropy between two random variables\n",
    "        \"\"\"\n",
    "        assert (x_index >= 0 and x_index <= self.n_rows)\n",
    "        assert (y_index >= 0 and y_index <= self.n_rows)\n",
    "        # Variable to return entropy\n",
    "        summation = 0.0\n",
    "        # Get unique values of random variables\n",
    "        values_x = set(self.data[x_index])\n",
    "        values_y = set(self.data[y_index])\n",
    "        # Print debug info\n",
    "        if debug:\n",
    "            print('Entropy between')\n",
    "            print(self.data[x_index])\n",
    "            print(self.data[y_index])\n",
    "        # For each random value pair\n",
    "        for value_x in values_x:\n",
    "            for value_y in values_y:\n",
    "                pxy = len(where(in1d(where(self.data[x_index] == value_x)[0], \n",
    "                                     where(self.data[y_index] == value_y)[0]) == True)[0]) / self.n_cols\n",
    "                if pxy > 0.0:\n",
    "                    summation += pxy * math.log(pxy, log_base)\n",
    "                if debug:\n",
    "                    print(f'({value_x},{value_y}) pxy:{pxy}')\n",
    "        if summation == 0.0:\n",
    "            return summation\n",
    "        else:\n",
    "            return -summation\n",
    "        \n",
    "        \n",
    "    def mutual_information(self, x_index, y_index, log_base, debug=False):\n",
    "        \"\"\"\n",
    "        Calculate and return Mutual Information between two random variables\n",
    "        \"\"\"\n",
    "        # Check if index are into the bounds\n",
    "        assert (x_index >= 0 and x_index <= self.n_rows)\n",
    "        assert (y_index >= 0 and y_index <= self.n_rows)\n",
    "        # Variable to return MI\n",
    "        summation = 0.0\n",
    "        # Get unique values of random variables\n",
    "        values_x = set(self.data[x_index])\n",
    "        values_y = set(self.data[y_index])\n",
    "        # Print debug info\n",
    "        if debug:\n",
    "            print('MI between')\n",
    "            print(self.data[x_index])\n",
    "            print(self.data[y_index])\n",
    "        # For each random value pair\n",
    "        for value_x in values_x:\n",
    "            for value_y in values_y:\n",
    "                px = shape(where(self.data[x_index] == value_x))[1] / self.n_cols\n",
    "                py = shape(where(self.data[y_index] == value_y))[1] / self.n_cols\n",
    "                pxy = len(where(in1d(where(self.data[x_index] == value_x)[0], \n",
    "                                     where(self.data[y_index] == value_y)[0]) == True)[0]) / self.n_cols\n",
    "                if pxy > 0.0:\n",
    "                    summation += pxy * math.log((pxy / (px * py)), log_base)\n",
    "                if debug:\n",
    "                    print(f'({value_x},{value_y}) px:{px} py:{py} pxy:{pxy}')\n",
    "        return summation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "import numpy as np\n",
    "import copy\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # de compositores restantes:  19\n"
     ]
    }
   ],
   "source": [
    "#dataframe datos de compositores \n",
    "\n",
    "datos_composers = {}\n",
    "carpeta = r'Sequences\\labels'\n",
    "archivos_en_carpeta = os.listdir(carpeta)\n",
    "index0 = 0\n",
    "indice = 0\n",
    "\n",
    "for archivo in archivos_en_carpeta:\n",
    "    ruta_completa = os.path.join(carpeta, archivo)\n",
    "    serie = pd.read_csv(ruta_completa, header = None)\n",
    "    composer = archivo.split('-')[1].capitalize() # nombre compositor\n",
    "    datos_composers[composer] = {} #genero bibio para composer\n",
    "    datos_composers[composer]['Birth_year'] = archivo.split('-')[0] #año de nacimiento\n",
    "    index1 = serie.iloc[0, 0].split('\\t')[0] #el # del primer serie del composer\n",
    "    index2 = int(serie.iloc[len(serie)-3, 0].split('\\t')[0]) - index0 # # Piezas\n",
    "    index0 = index2 + index0 # numero total de piezas anteriores\n",
    "    datos_composers[composer]['# Piezas'] = index2 # Piezas\n",
    "    datos_composers[composer]['Indice'] = indice\n",
    "    indice += 1\n",
    "\n",
    "composers = {}\n",
    "M = 0\n",
    "carpeta = r'Sequences\\Series'\n",
    "archivos_en_carpeta = os.listdir(carpeta)\n",
    "\n",
    "for archivo in archivos_en_carpeta:\n",
    "    ruta_completa = os.path.join(carpeta, archivo)\n",
    "    serie = pd.read_csv(ruta_completa)\n",
    "    # escoge una serie\n",
    "    composer = archivo.split('-')[1].capitalize() # nombre compositor\n",
    "    composers[composer] = {}\n",
    "\n",
    "    for pieza in range( datos_composers[composer]['# Piezas'] ):\n",
    "        N = serie.iloc[0, 0].split('\\t')[1] # # de elementos por pieza\n",
    "        M = int(N) + M\n",
    "        index_n1 = 0 \n",
    "        index_n2 = int(N)+2 \n",
    "        serie_n = serie[index_n1 + 2:index_n2].reset_index(drop=True) # resetear index\n",
    "        serie = serie[index_n2 +1:] # recortar serie Original\n",
    "        serie_n.index += 1 # que index empiece desde 1\n",
    "        num_serie_T = serie.columns[0]  # numero de serie de todo el dataset\n",
    "        num_serie = pieza + 1\n",
    "        composers[composer]['Serie_'+str(num_serie)] = serie_n.squeeze().to_numpy().astype(float) # agregamos pieza al dicc composer con key como # serie\n",
    "\n",
    "###\n",
    "###\n",
    "\n",
    "composers_depurado = copy.deepcopy(composers)\n",
    "datos_composers_depurado = copy.deepcopy(datos_composers)\n",
    "\n",
    "for i,composer in enumerate(composers.keys()):\n",
    "    d = 0\n",
    "    for pieza in composers[composer].keys():\n",
    "        if len(composers[composer][pieza])//2 < 400:\n",
    "            del composers_depurado[composer][pieza]\n",
    "            d = d + 1\n",
    "    datos_composers_depurado[composer]['# Piezas'] = datos_composers[composer]['# Piezas'] - d\n",
    "\n",
    "\n",
    "# 40 promedio de numero de piezas por compositor\n",
    "composers_depurado_v2 = copy.deepcopy(composers_depurado)\n",
    "composers_depurado_v2_keychange = copy.deepcopy(composers_depurado_v2)\n",
    "datos_composers_depurado_v2 = copy.deepcopy(datos_composers_depurado)\n",
    "\n",
    "for composer in composers.keys():\n",
    "    if datos_composers_depurado[composer]['# Piezas'] < 30:\n",
    "        del composers_depurado_v2[composer]\n",
    "        del datos_composers_depurado_v2[composer]\n",
    "    \n",
    "for i,composer in enumerate(composers_depurado_v2.keys()):\n",
    "    datos_composers_depurado_v2[composer]['Indice'] = i \n",
    "\n",
    "for composer in composers_depurado_v2.keys():\n",
    "    for i,serie in enumerate(composers_depurado_v2[composer].keys()):\n",
    "        composers_depurado_v2_keychange[composer]['Serie_' + str(i+1)] = composers_depurado_v2_keychange[composer].pop(serie)\n",
    "\n",
    "print(\" # de compositores restantes: \", len(composers_depurado_v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2(x):\n",
    "    x[x == 0] = 1  # Evitar problemas con log(0)\n",
    "    return np.log2(x)\n",
    "\n",
    "# Función para calcular la información mutua\n",
    "def calcular_informacion_mutua(x, y, bins=20):\n",
    "    # Discretizar ambas variables en bins\n",
    "    hist_conj, edges_x, edges_y = np.histogram2d(x, y, bins=bins)\n",
    "    prob_conj = hist_conj / np.sum(hist_conj)  # Probabilidad conjunta\n",
    "\n",
    "    # Probabilidades marginales\n",
    "    prob_x = np.sum(prob_conj, axis=1)  # Marginal en X\n",
    "    prob_y = np.sum(prob_conj, axis=0)  # Marginal en Y\n",
    "\n",
    "    # Entropías\n",
    "    H_x = -np.sum(prob_x * log2(prob_x))\n",
    "    H_y = -np.sum(prob_y * log2(prob_y))\n",
    "    H_conj = -np.sum(prob_conj * log2(prob_conj))\n",
    "\n",
    "    # Información mutua\n",
    "    I_xy = H_x + H_y - H_conj\n",
    "    return I_xy, H_x, H_y, H_conj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.10575395309166691, 3.9597427501269404, 3.0885452854191504, 6.942534082454424)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "Js = np.load('J_composers_global.npy')\n",
    "xi = np.load('xi_index_global.npy')\n",
    "# data2 = np.array([\n",
    "#     generar_uniforme_centrada(2677, 1e-6),  # Variable X\n",
    "#     generar_uniforme_centrada(2677, 1e-6)   # Variable Y\n",
    "data2 = np.array([\n",
    "    np.array(np.linspace(-200,200,1000)),  # Variable X\n",
    "    (np.linspace(-200,200,1000)**2)   # Variable Y\n",
    "])\n",
    "\n",
    "pts_interp = 15\n",
    "Js = np.array([])\n",
    "for composer in composers_depurado_v2.keys():\n",
    "        array = 1-np.load('J_hermite_sincorte_depurado/interp_'+str(pts_interp)+'/'+ str(datos_composers[composer]['Birth_year']) + '_J_interp_' + str(composer) + '_herm.npy')\n",
    "        Js = np.concatenate((Js,array))\n",
    "Js_random = data2[0,:]\n",
    "null = []\n",
    "print(calcular_informacion_mutua(Js,xi))\n",
    "# for _ in range(1000):\n",
    "#     for i in range(100):\n",
    "#         random.shuffle(Js_random)\n",
    "#     null.append(calcular_informacion_mutua(Js_random,data2[1,:])[0])\n",
    "#     print(len(null))\n",
    "# MI_index = np.abs(calcular_informacion_mutua(data2[0,:],data2[1,:])[0]- np.mean(null))/np.std(null)\n",
    "# MI_index\n",
    "\n",
    "#2 0.04934371108605262\n",
    "#3 0.04755197883631457\n",
    "#4 0.054119239172703004\n",
    "#5 0.057229357687264226\n",
    "#15 0.05934594566672313\n",
    "# no mecetas 0.05444613157353828\n",
    "#3: 0.04698538041088529\n",
    "\n",
    "# calcular_informacion_mutua(data2[0,:],data2[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Js = np.load('J_composers_global.npy')\n",
    "xi = np.load('xi_index_global.npy')\n",
    "print(xi)\n",
    "# Define tus datos en forma de array\n",
    "data = np.array([\n",
    "    np.load('xi_index_global.npy'),  # Variable X\n",
    "    np.load('J_composers_lineal_global.npy')   # Variable Y\n",
    "])\n",
    "print(np.shape(data))\n",
    "# np.load('J_composers_lineal_global')\n",
    "# np.load('J_composers_hermite_global')\n",
    "\n",
    "\n",
    "# Crear el objeto InformationTheoryTool\n",
    "it_tool = InformationTheoryTool(data)\n",
    "\n",
    "# Calcular la información mutua entre X (fila 0) e Y (fila 1)\n",
    "mi = it_tool.mutual_information(0, 1, 2)  # Base 2 para bits\n",
    "print(f\"Información mutua entre X e Y: {mi:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_uniforme_centrada(n, varianza):\n",
    "    # Calcular el límite superior e inferior de la distribución uniforme\n",
    "    limite = np.sqrt(varianza)\n",
    "    # Generar n números aleatorios con distribución uniforme entre -limite y limite\n",
    "    return np.random.uniform(-limite, limite, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# data2 = np.array([\n",
    "#     generar_uniforme_centrada(2677, 1e-6),  # Variable X\n",
    "#     generar_uniforme_centrada(2677, 1e-6)   # Variable Y\n",
    "# ])\n",
    "# print(np.shape(data))\n",
    "# np.load('J_composers_lineal_global')\n",
    "# np.load('J_composers_hermite_global')\n",
    "data2 = np.array([\n",
    "    np.array(np.linspace(-200,200,1000)),  # Variable X\n",
    "    (np.linspace(-200,200,1000))   # Variable Y\n",
    "])\n",
    "\n",
    "# Crear el objeto InformationTheoryTool\n",
    "# it_tool2 = InformationTheoryTool(data2)\n",
    "\n",
    "# # Calcular la información mutua entre X (fila 0) e Y (fila 1)\n",
    "# mi2 = it_tool2.mutual_information(0, 1, 2)  # Base 2 para bits\n",
    "# print(f\"Información mutua entre X e Y: {mi2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mutual_information(X, Y):\n",
    "    \"\"\"\n",
    "    Calcula la información mutua discreta entre dos variables aleatorias X e Y.\n",
    "\n",
    "    Parámetros:\n",
    "        X (array-like): Variable aleatoria discreta 1.\n",
    "        Y (array-like): Variable aleatoria discreta 2.\n",
    "\n",
    "    Retorna:\n",
    "        float: Información mutua entre X e Y.\n",
    "    \"\"\"\n",
    "    # Asegurarse de que X e Y sean numpy arrays\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    \n",
    "    # Obtener los valores únicos y sus conteos para las distribuciones marginales\n",
    "    unique_x, counts_x = np.unique(X, return_counts=True)\n",
    "    unique_y, counts_y = np.unique(Y, return_counts=True)\n",
    "    \n",
    "    # Calcular las probabilidades marginales\n",
    "    p_x = counts_x / len(X)\n",
    "    p_y = counts_y / len(Y)\n",
    "    \n",
    "    # Crear una matriz conjunta\n",
    "    joint_counts = np.zeros((len(unique_x), len(unique_y)))\n",
    "    \n",
    "    for i, x_val in enumerate(unique_x):\n",
    "        for j, y_val in enumerate(unique_y):\n",
    "            joint_counts[i, j] = np.sum((X == x_val) & (Y == y_val))\n",
    "    \n",
    "    # Convertir los conteos conjuntos a probabilidades\n",
    "    p_xy = joint_counts / len(X)\n",
    "    \n",
    "    # Calcular la información mutua\n",
    "    mi = 0\n",
    "    for i in range(len(unique_x)):\n",
    "        for j in range(len(unique_y)):\n",
    "            if p_xy[i, j] > 0:  # Evitar log(0)\n",
    "                mi += p_xy[i, j] * np.log(p_xy[i, j] / (p_x[i] * p_y[j]))\n",
    "    \n",
    "    return mi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Ruta de la carpeta con los archivos\n",
    "carpeta = r'Contenido'\n",
    "\n",
    "# Función para calcular log2, evitando problemas con ceros\n",
    "def log2(x):\n",
    "    x[x == 0] = 1  # Evita log2(0)\n",
    "    return np.log2(x)\n",
    "\n",
    "# Función para discretizar datos continuos en bins\n",
    "def discretizar_datos(data, bins=10):\n",
    "    data_discretizada = np.digitize(data, bins=np.linspace(np.min(data), np.max(data), bins))\n",
    "    return data_discretizada\n",
    "\n",
    "# Función para calcular información mutua entre dos variables\n",
    "def calcular_informacion_mutua(data, bins=10):\n",
    "    # Discretizar los datos continuos\n",
    "    valores_discretizados = discretizar_datos(data[:, 1], bins=bins)\n",
    "    \n",
    "    # Obtener valores únicos y calcular probabilidades marginales\n",
    "    valores_unicos, conteos = np.unique(valores_discretizados, return_counts=True)\n",
    "    prob = conteos / np.sum(conteos)\n",
    "    \n",
    "    # Calcular bigramas y frecuencias conjuntas\n",
    "    bigramas = list(ngrams(valores_discretizados, 2))\n",
    "    frecuencias_bigrama = FreqDist(bigramas)\n",
    "    \n",
    "    # Crear matriz de frecuencias conjuntas\n",
    "    matrix_counts = np.zeros((len(valores_unicos), len(valores_unicos)))\n",
    "    for bigrama, frecuencia in frecuencias_bigrama.items():\n",
    "        pos1 = np.where(valores_unicos == bigrama[0])[0][0]\n",
    "        pos2 = np.where(valores_unicos == bigrama[1])[0][0]\n",
    "        matrix_counts[pos1, pos2] = frecuencia\n",
    "    \n",
    "    # Convertir frecuencias conjuntas a probabilidades conjuntas\n",
    "    matrix_conj = matrix_counts / len(bigramas)\n",
    "    \n",
    "    # Calcular probabilidades marginales\n",
    "    prob_x = np.sum(matrix_conj, axis=1)\n",
    "    prob_y = np.sum(matrix_conj, axis=0)\n",
    "    \n",
    "    # Calcular entropías marginales y conjuntas\n",
    "    Ent_x = -np.sum(prob_x * log2(prob_x))\n",
    "    Ent_y = -np.sum(prob_y * log2(prob_y))\n",
    "    Ent_conj = -np.sum(matrix_conj * log2(matrix_conj))\n",
    "    \n",
    "    # Calcular información mutua\n",
    "    Inf_mut = Ent_x + Ent_y - Ent_conj\n",
    "    return Inf_mut\n",
    "\n",
    "# Leer archivos de la carpeta y calcular información mutua\n",
    "archivos_en_carpeta = os.listdir(carpeta)\n",
    "resultados = {}\n",
    "\n",
    "for archivo in archivos_en_carpeta:\n",
    "    ruta_completa = os.path.join(carpeta, archivo)\n",
    "    data = np.genfromtxt(ruta_completa)\n",
    "    # Calcular información mutua con 10 bins\n",
    "    mi = calcular_informacion_mutua(data, bins=10)\n",
    "    resultados[archivo] = mi\n",
    "\n",
    "# Imprimir resultados\n",
    "for archivo, mi in resultados.items():\n",
    "    print(f\"La información mutua del archivo {archivo} es: {mi}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_information(data2[0,:], data2[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Js = np.load('J_composers_global.npy')\n",
    "xi = np.load('xi_index_global.npy')\n",
    "mutual_information(Js, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Js, xi, '.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
